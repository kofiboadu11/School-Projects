{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd687e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 8.5\n",
      "Delta: 3.5\n",
      "Delta: 2.4499999999999993\n",
      "Delta: 1.7149999999999999\n",
      "Delta: 1.2005\n",
      "Delta: 0\n",
      "Optimal Q-values after convergence:\n",
      "State (0, 0):\n",
      "  Action right: Q = 0.00\t  Action left: Q = 0.00\t  Action up: Q = 0.00\t  Action down: Q = 0.00\t\n",
      "State (0, 1):\n",
      "  Action right: Q = -5.00\t  Action left: Q = -10.95\t  Action up: Q = -8.50\t  Action down: Q = -10.95\t\n",
      "State (0, 2):\n",
      "  Action right: Q = -8.50\t  Action left: Q = -12.66\t  Action up: Q = -10.95\t  Action down: Q = -12.66\t\n",
      "State (0, 3):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -13.87\t  Action up: Q = -12.66\t  Action down: Q = -13.87\t\n",
      "State (0, 4):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -13.87\t  Action up: Q = -13.87\t  Action down: Q = -12.66\t\n",
      "State (1, 0):\n",
      "  Action right: Q = -8.50\t  Action left: Q = -10.95\t  Action up: Q = -5.00\t  Action down: Q = -10.95\t\n",
      "State (1, 1):\n",
      "  Action right: Q = -8.50\t  Action left: Q = -12.66\t  Action up: Q = -8.50\t  Action down: Q = -12.66\t\n",
      "State (1, 2):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -13.87\t  Action up: Q = -10.95\t  Action down: Q = -13.87\t\n",
      "State (1, 3):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -12.66\t  Action up: Q = -12.66\t  Action down: Q = -12.66\t\n",
      "State (1, 4):\n",
      "  Action right: Q = -13.87\t  Action left: Q = -12.66\t  Action up: Q = -13.87\t  Action down: Q = -10.95\t\n",
      "State (2, 0):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -12.66\t  Action up: Q = -8.50\t  Action down: Q = -12.66\t\n",
      "State (2, 1):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -13.87\t  Action up: Q = -10.95\t  Action down: Q = -13.87\t\n",
      "State (2, 2):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -12.66\t  Action up: Q = -12.66\t  Action down: Q = -12.66\t\n",
      "State (2, 3):\n",
      "  Action right: Q = -13.87\t  Action left: Q = -10.95\t  Action up: Q = -13.87\t  Action down: Q = -10.95\t\n",
      "State (2, 4):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -10.95\t  Action up: Q = -12.66\t  Action down: Q = -8.50\t\n",
      "State (3, 0):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -13.87\t  Action up: Q = -10.95\t  Action down: Q = -13.87\t\n",
      "State (3, 1):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -12.66\t  Action up: Q = -12.66\t  Action down: Q = -12.66\t\n",
      "State (3, 2):\n",
      "  Action right: Q = -13.87\t  Action left: Q = -10.95\t  Action up: Q = -13.87\t  Action down: Q = -10.95\t\n",
      "State (3, 3):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -8.50\t  Action up: Q = -12.66\t  Action down: Q = -8.50\t\n",
      "State (3, 4):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -8.50\t  Action up: Q = -10.95\t  Action down: Q = -5.00\t\n",
      "State (4, 0):\n",
      "  Action right: Q = -13.87\t  Action left: Q = -12.66\t  Action up: Q = -12.66\t  Action down: Q = -13.87\t\n",
      "State (4, 1):\n",
      "  Action right: Q = -13.87\t  Action left: Q = -10.95\t  Action up: Q = -13.87\t  Action down: Q = -12.66\t\n",
      "State (4, 2):\n",
      "  Action right: Q = -12.66\t  Action left: Q = -8.50\t  Action up: Q = -12.66\t  Action down: Q = -10.95\t\n",
      "State (4, 3):\n",
      "  Action right: Q = -10.95\t  Action left: Q = -5.00\t  Action up: Q = -10.95\t  Action down: Q = -8.50\t\n",
      "State (4, 4):\n",
      "  Action right: Q = 0.00\t  Action left: Q = 0.00\t  Action up: Q = 0.00\t  Action down: Q = 0.00\t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Actions\n",
    "A = ['right', 'left', 'up', 'down']\n",
    "\n",
    "\n",
    "Q = np.zeros((5, 5, len(A)))\n",
    "\n",
    "\n",
    "R = -5\n",
    "\n",
    "\n",
    "gamma = 0.7\n",
    "\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    i, j = state\n",
    "    if action == 'up' and i > 0:\n",
    "        return (i - 1, j)\n",
    "    elif action == 'down' and i < 4:\n",
    "        return (i + 1, j)\n",
    "    elif action == 'right' and j > 0:\n",
    "        return (i, j - 1)\n",
    "    elif action == 'left' and j < 4:\n",
    "        return (i, j + 1)\n",
    "    else:\n",
    "        return state  \n",
    "\n",
    "\n",
    "def is_terminal_state(state):\n",
    "    \n",
    "    return state == (0, 0) or state == (4, 4)\n",
    "\n",
    "# Value iteration algorithm\n",
    "def value_iteration():\n",
    "    delta = float('inf')\n",
    "    threshold = 0.001  \n",
    "    while delta > threshold:\n",
    "        delta = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                state = (i, j)\n",
    "                if is_terminal_state(state):\n",
    "                    continue \n",
    "                \n",
    "                for k, action in enumerate(A):\n",
    "                    next_state = get_next_state(state, action)\n",
    "                    reward = R \n",
    "                    \n",
    "                   \n",
    "                    next_action_values = [Q[next_state[0], next_state[1], l] for l in range(len(A))]\n",
    "                    max_next_action_value = max(next_action_values)\n",
    "                    new_value = reward + gamma * max_next_action_value\n",
    "                    \n",
    "                    \n",
    "                    difference = abs(Q[i, j, k] - new_value)\n",
    "                    Q[i, j, k] = new_value\n",
    "                    delta = max(delta, difference)\n",
    "                    \n",
    "        print(f\"Delta: {delta}\")\n",
    "\n",
    "  \n",
    "    print(\"Optimal Q-values after convergence:\")\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            print(f\"State ({i}, {j}):\")\n",
    "            for k, action in enumerate(A):\n",
    "                print(f\"  Action {action}: Q = {Q[i, j, k]:.2f}\", end=\"\\t\")\n",
    "            print()\n",
    "\n",
    "value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ab94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
